"""Utility script to sanity-check multiprocessing behaviour on the current system."""
# Please put the file back into the src folder before use.

from __future__ import annotations

import argparse
import multiprocessing as mp
import os
import platform
import sys
import time
from statistics import mean

import torch


def _probe_task(task_id: int, device_index: int, cpu_sleep: float, matmul_size: int) -> float:
    """Worker task that mixes CPU waiting with GPU matmul to expose scheduling issues."""

    pid = os.getpid()
    now = time.time()
    print(f"[Probe] pid={pid} task={task_id} start={now:.3f}s", flush=True)
    if cpu_sleep > 0:
        time.sleep(cpu_sleep)

    device: torch.device
    if torch.cuda.is_available():
        device = torch.device(f"cuda:{device_index}")
        torch.cuda.set_device(device_index)
    else:
        device = torch.device("cpu")

    start = time.perf_counter()
    size = matmul_size
    a = torch.randn((size, size), device=device)
    b = torch.randn((size, size), device=device)
    for step in range(3):
        a = torch.matmul(a, b)
        if device.type == "cuda":
            torch.cuda.synchronize()
        step_time = time.time()
        print(
            f"[Probe] pid={pid} task={task_id} step={step} timestamp={step_time:.3f}s",
            flush=True,
        )
    duration = time.perf_counter() - start
    done = time.time()
    print(f"[Probe] pid={pid} task={task_id} done={done:.3f}s elapsed={duration:.3f}s", flush=True)
    return duration


def _heavy_pinn_task(task_id: int, device_index: int, epochs: int = 1000) -> float:
    """æ¨¡æ‹Ÿé‡è´Ÿè½½ PINN è®­ç»ƒä»»åŠ¡ï¼Œç”¨äºçœŸå®æ€§èƒ½æµ‹è¯•"""
    pid = os.getpid()
    if torch.cuda.is_available():
        device = torch.device(f"cuda:{device_index}")
        torch.cuda.set_device(device_index)
        # è½»é‡é¢„çƒ­ï¼Œé¿å…é¦–æ¬¡å»ºç«‹ CUDA ä¸Šä¸‹æ–‡çš„æŠ–åŠ¨/å‘Šè­¦
        _ = torch.randn(8, 8, device=device) @ torch.randn(8, 8, device=device)
        torch.cuda.synchronize()
    else:
        device = torch.device("cpu")
    
    # æ„å»ºæ¥è¿‘å®é™…çš„æ·±åº¦ç¥ç»ç½‘ç»œ
    model = torch.nn.Sequential(
        torch.nn.Linear(2, 128),
        torch.nn.Tanh(),
        torch.nn.Linear(128, 128),
        torch.nn.Tanh(),
        torch.nn.Linear(128, 128),
        torch.nn.Tanh(),
        torch.nn.Linear(128, 1)
    ).to(device)
    
    optimizer = torch.optim.Adam(model.parameters())
    
    start = time.perf_counter()
    
    # æ¨¡æ‹ŸæŒ‡å®šæ•°é‡çš„è®­ç»ƒ epochs
    for epoch in range(epochs):
        # æ¨¡æ‹Ÿ CPU æ•°æ®å‡†å¤‡é˜¶æ®µ
        time.sleep(0.002)
        
        # GPU å¯†é›†è®¡ç®—ï¼šå‰å‘ä¼ æ’­ + æ¢¯åº¦è®¡ç®—
        x = torch.randn(512, 2, device=device, requires_grad=True)
        u = model(x)
        
        # è®¡ç®—ä¸€é˜¶å¯¼æ•°ï¼ˆPINN ç‰¹æœ‰ï¼‰
        grad_u = torch.autograd.grad(
            outputs=u, 
            inputs=x,
            grad_outputs=torch.ones_like(u),
            create_graph=True
        )[0]
        
        # è®¡ç®—äºŒé˜¶å¯¼æ•°ï¼ˆPINN ç‰¹æœ‰ï¼‰
        grad2_u = torch.autograd.grad(
            outputs=grad_u[:, 0].sum(),
            inputs=x,
            create_graph=True
        )[0]
        
        # æŸå¤±å‡½æ•°å’Œåå‘ä¼ æ’­
        loss = (u ** 2).mean() + (grad2_u ** 2).mean()
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        if device.type == "cuda":
            torch.cuda.synchronize()
        
        # å®šæœŸæ‰“å°è¿›åº¦
        if epoch % 50 == 0:
            print(f"[Heavy] pid={pid} task={task_id} epoch={epoch}/{epochs} loss={loss.item():.6f}", flush=True)
    
    duration = time.perf_counter() - start
    if device.type == "cuda":
        torch.cuda.synchronize()
    
    print(f"[Heavy] pid={pid} task={task_id} completed in {duration:.3f}s", flush=True)
    return duration


def _log_environment_info(workers: int) -> None:
    print("=" * 72)
    print("Auto-PINN Parallel Diagnostics")
    print("=" * 72)
    print(f"Python version : {sys.version.split()[0]}")
    print(f"Torch version  : {torch.__version__}")
    print(f"Platform       : {platform.platform()}")
    print(f"CUDA available : {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        props = torch.cuda.get_device_properties(device)
        print(f"CUDA device    : {props.name} (index {device})")
        print(f"Total memory   : {props.total_memory / 1024 ** 3:.2f} GiB")
    print(f"Requested workers: {workers}")
    print("Multiprocessing start methods available:")
    for method in mp.get_all_start_methods():
        print(f"  - {method}")
    try:
        current_method = mp.get_start_method(allow_none=True)
    except ValueError:
        current_method = None
    print(f"Current start method (before diagnostics): {current_method}")
    print("=" * 72)


def run_probe(workers: int, tasks: int, cpu_sleep: float, matmul_size: int) -> None:
    ctx = mp.get_context("spawn")
    _log_environment_info(workers)
    print("[Main] Launching diagnostic pool...")
    start = time.perf_counter()
    with ctx.Pool(processes=workers) as pool:
        payloads = [
            (task_id, 0, cpu_sleep, matmul_size)
            for task_id in range(tasks)
        ]
        print(
            f"[Main] Submitting {len(payloads)} tasks with spawn start method...",
            flush=True,
        )
        results = list(pool.starmap(_probe_task, payloads))
    total = time.perf_counter() - start
    print("=" * 72)
    print("Diagnostics summary")
    print(f"Tasks completed  : {len(results)}")
    print(f"Average task time: {mean(results):.3f}s")
    print(f"Total wall time  : {total:.3f}s")
    theoretical = mean(results) * (len(results) / max(1, workers))
    print(f"Ideal wall time (perfect overlap): {theoretical:.3f}s")
    print("If total wall time is close to ideal, workers are overlapping correctly.")
    print("Review timestamps above: overlapping start times indicate parallel execution.")
    print("=" * 72)


def benchmark_workers(max_workers: int = 8, tasks_per_worker: int = 2, epochs: int = 1000) -> None:
    """å¯¹æ¯”ä¸åŒ Workers æ•°é‡çš„æ€§èƒ½ï¼Œæ‰¾å‡ºæœ€ä¼˜é…ç½®
    
    å…³é”®æŒ‡æ ‡è¯´æ˜:
    - ååé‡åŠ é€Ÿæ¯” = (workers=N çš„ä»»åŠ¡æ•° / workers=N çš„æ€»è€—æ—¶) / (workers=1 çš„ä»»åŠ¡æ•° / workers=1 çš„æ€»è€—æ—¶)
    - ç®€åŒ–å = (N Ã— tasks_per_worker / time_N) / (tasks_per_worker / time_1)
    - å†ç®€åŒ– = N Ã— time_1 / time_N
    """
    print("\n" + "="*72)
    print("WORKERS SCALABILITY BENCHMARK (ååé‡æµ‹è¯•)")
    print("="*72)
    print(f"æµ‹è¯•èŒƒå›´: 1 åˆ° {max_workers} workers")
    print(f"æ¯ä¸ªé…ç½®è¿è¡Œçš„ä»»åŠ¡æ•° = workers Ã— {tasks_per_worker}")
    print(f"æ¯ä¸ªä»»åŠ¡è®­ç»ƒ {epochs} epochs")
    print(f"æ³¨æ„: Workers è¶Šå¤šï¼Œæ€»ä»»åŠ¡æ•°è¶Šå¤šï¼Œè¿™æ ·æ‰èƒ½æµ‹è¯•ååé‡ï¼")
    print("="*72 + "\n")
    
    results = {}  # {workers: (total_time, num_tasks, avg_task_time)}
    
    for workers in range(1, max_workers + 1):
        print(f"\n{'='*72}")
        print(f"Testing with {workers} workers...")
        print(f"{'='*72}")
        
        ctx = mp.get_context("spawn")
        num_tasks = workers * tasks_per_worker
        
        start = time.perf_counter()
        with ctx.Pool(processes=workers) as pool:
            task_durations = pool.starmap(
                _heavy_pinn_task,
                [(i, 0, epochs) for i in range(num_tasks)]
            )
        total_time = time.perf_counter() - start
        
        avg_task_time = mean(task_durations)
        
        # è®¡ç®—ååé‡ (ä»»åŠ¡æ•°/ç§’)
        throughput = num_tasks / total_time
        
        # è®¡ç®—ååé‡åŠ é€Ÿæ¯” (ç›¸å¯¹äº workers=1)
        if 1 in results:
            baseline_throughput = results[1][1] / results[1][0]  # ä»»åŠ¡æ•° / æ€»æ—¶é—´
            throughput_speedup = throughput / baseline_throughput
            efficiency = throughput_speedup / workers * 100
        else:
            throughput_speedup = 1.0
            efficiency = 100.0
        
        results[workers] = (total_time, num_tasks, avg_task_time)
        
        print(f"\n{'='*72}")
        print(f"Workers={workers} ç»“æœ:")
        print(f"  å®Œæˆä»»åŠ¡æ•°: {num_tasks} ä¸ª")
        print(f"  æ€»è€—æ—¶: {total_time:.2f}s")
        print(f"  ååé‡: {throughput:.3f} ä»»åŠ¡/ç§’")
        print(f"  å¹³å‡å•ä»»åŠ¡æ—¶é—´: {avg_task_time:.2f}s")
        print(f"  ååé‡åŠ é€Ÿæ¯”: {throughput_speedup:.2f}x (ç›¸å¯¹äº workers=1)")
        print(f"  å¹¶è¡Œæ•ˆç‡: {efficiency:.1f}%")
        print(f"{'='*72}")
    
    # æ±‡æ€»è¡¨æ ¼
    print("\n" + "="*72)
    print("SUMMARY TABLE (ååé‡å¯¹æ¯”)")
    print("="*72)
    print(f"{'Workers':<10} {'ä»»åŠ¡æ•°':<10} {'æ€»è€—æ—¶(s)':<12} {'ååé‡':<15} {'åŠ é€Ÿæ¯”':<10} {'å¹¶è¡Œæ•ˆç‡':<12}")
    print("-"*72)
    
    baseline_time, baseline_tasks, _ = results[1]
    baseline_throughput = baseline_tasks / baseline_time
    
    for workers in sorted(results.keys()):
        total_time, num_tasks, _ = results[workers]
        throughput = num_tasks / total_time
        speedup = throughput / baseline_throughput
        efficiency = speedup / workers * 100
        
        print(f"{workers:<10} {num_tasks:<10} {total_time:<12.2f} {throughput:<15.3f} {speedup:<10.2f}x {efficiency:<12.1f}%")
    print("="*72)
    
    # æ‰¾å‡ºæœ€ä¼˜é…ç½®
    best_workers = max(results.keys(), key=lambda w: (results[w][1] / results[w][0]) / baseline_throughput)
    best_time, best_tasks, _ = results[best_workers]
    best_throughput = best_tasks / best_time
    best_speedup = best_throughput / baseline_throughput
    
    print(f"\nâœ… æ¨èé…ç½®: workers={best_workers}")
    print(f"   ååé‡åŠ é€Ÿæ¯”: {best_speedup:.2f}x")
    print(f"   å¹¶è¡Œæ•ˆç‡: {best_speedup / best_workers * 100:.1f}%")
    print(f"   å®é™…æ„ä¹‰: åœ¨é—ä¼ ç®—æ³•ä¸­ï¼Œå®Œæˆç§ç¾¤è¯„ä¼°çš„é€Ÿåº¦æå‡ {best_speedup:.2f} å€\n")
    
    # æ€§èƒ½å»ºè®®
    print("="*72)
    print("æ€§èƒ½å»ºè®®:")
    print("="*72)
    
    if best_speedup < 1.2:
        print("âš ï¸  å¤šè¿›ç¨‹æ”¶ç›Šå¾ˆå°ï¼ˆ<20%ï¼‰ï¼Œå»ºè®®ä½¿ç”¨ workers=1")
        print("    åŸå› : GPU è®¡ç®—å·²é¥±å’Œï¼Œæˆ–ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€è¿‡å¤§")
        print("    å»ºè®®: ä¸“æ³¨äºç¼“å­˜å’Œå»é‡ä¼˜åŒ–")
    elif best_workers <= 2:
        print(f"âœ… workers={best_workers} æœ€ä¼˜")
        print(f"    åœ¨é—ä¼ ç®—æ³•ä¸­å¯ä»¥å®ç° {best_speedup:.2f}x çš„æ•´ä½“åŠ é€Ÿ")
        print(f"    å»ºè®®: ä½¿ç”¨ config.runtime.workers={best_workers}")
    else:
        print(f"âœ… workers={best_workers} æœ€ä¼˜")
        print(f"    ååé‡æå‡ {best_speedup:.2f}xï¼Œå¹¶è¡Œæ•ˆç‡ {best_speedup / best_workers * 100:.1f}%")
        print(f"    å»ºè®®: ä½¿ç”¨ config.runtime.workers={best_workers}")
    
    # æ˜¾ç¤ºå®é™…åº”ç”¨åœºæ™¯
    print(f"\nğŸ“Š å®é™…åº”ç”¨ç¤ºä¾‹ (å‡è®¾ç§ç¾¤å¤§å°=20):")
    print(f"   Workers=1: å®Œæˆä¸€ä»£è¯„ä¼°éœ€è¦ ~{baseline_time * 20 / baseline_tasks:.1f}ç§’")
    print(f"   Workers={best_workers}: å®Œæˆä¸€ä»£è¯„ä¼°éœ€è¦ ~{best_time * 20 / best_tasks:.1f}ç§’")
    savings = (baseline_time * 20 / baseline_tasks) - (best_time * 20 / best_tasks)
    print(f"   æ¯ä»£èŠ‚çœ: ~{savings:.1f}ç§’")
    print(f"   15ä»£èŠ‚çœ: ~{savings * 15 / 60:.1f}åˆ†é’Ÿ")
    
    # è­¦å‘Šä¿¡æ¯
    if max_workers > best_workers:
        worst_workers = max_workers
        worst_time, worst_tasks, _ = results[worst_workers]
        worst_throughput = worst_tasks / worst_time
        worst_speedup = worst_throughput / baseline_throughput
        regression = (best_speedup - worst_speedup) / best_speedup * 100
        if regression > 10:
            print(f"\nâš ï¸  è­¦å‘Š: workers={worst_workers} æ¯” workers={best_workers} æ…¢äº† {regression:.1f}%")
            print(f"    åŸå› : è¿‡å¤šè¿›ç¨‹å¯¼è‡´è°ƒåº¦å¼€é”€è¶…è¿‡å¹¶è¡Œæ”¶ç›Š")
    print("="*72 + "\n")


def benchmark_fixed_tasks(max_workers: int = 8, total_tasks: int = 20, epochs: int = 1000) -> None:
    """å›ºå®šæ€»ä»»åŠ¡æ•°çš„åŸºå‡†æµ‹è¯•ï¼šè´´è¿‘ GA ä¸€ä»£è¯„ä¼°çœŸå®å¢™é’Ÿæ—¶é—´ã€‚

    å¯¹äºæ¯ä¸ª workers é…ç½®ï¼Œéƒ½å®Œæˆç›¸åŒæ•°é‡çš„ä»»åŠ¡ï¼ˆtotal_tasksï¼‰ï¼Œ
    ç›´æ¥æ¯”è¾ƒå®Œæˆè¿™äº›ä»»åŠ¡æ‰€éœ€çš„æ€»æ—¶é—´ï¼ˆå¢™é’Ÿæ—¶é—´ï¼‰ã€‚
    """
    print("\n" + "="*72)
    print("FIXED-TOTAL-TASKS BENCHMARK (åŒä»»åŠ¡é‡å¢™é’Ÿæ—¶é—´)")
    print("="*72)
    print(f"æ¯ä¸ªé…ç½®çš„æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print(f"æ¯ä¸ªä»»åŠ¡ epochs: {epochs}")
    print("="*72 + "\n")

    results = {}  # {workers: (total_time, avg_task_time)}
    baseline_time = None

    for workers in range(1, max_workers + 1):
        print(f"\n{'='*72}")
        print(f"Testing with {workers} workers...")
        print(f"{'='*72}")
        ctx = mp.get_context("spawn")
        start = time.perf_counter()
        with ctx.Pool(processes=workers) as pool:
            durations = pool.starmap(_heavy_pinn_task, [(i, 0, epochs) for i in range(total_tasks)])
        total_time = time.perf_counter() - start
        avg_task_time = mean(durations)
        results[workers] = (total_time, avg_task_time)
        if baseline_time is None:
            baseline_time = total_time
        speedup = baseline_time / total_time
        efficiency = speedup / workers * 100
        print(f"\nWorkers={workers} ç»“æœ:")
        print(f"  å®Œæˆç›¸åŒä»»åŠ¡æ•°: {total_tasks} ä¸ª")
        print(f"  æ€»è€—æ—¶(å¢™é’Ÿ): {total_time:.2f}s")
        print(f"  å¹³å‡å•ä»»åŠ¡: {avg_task_time:.2f}s")
        print(f"  é€Ÿåº¦æå‡(ç›¸å¯¹W=1): {speedup:.2f}x")
        print(f"  å¹¶è¡Œæ•ˆç‡: {efficiency:.1f}%")
        print(f"{'='*72}")

    print("\n" + "="*72)
    print("SUMMARY TABLE (å›ºå®šä»»åŠ¡æ•°)")
    print("="*72)
    print(f"{'Workers':<10} {'æ€»è€—æ—¶(s)':<12} {'é€Ÿåº¦æå‡':<10} {'å¹¶è¡Œæ•ˆç‡':<12}")
    print("-"*72)
    for w in sorted(results.keys()):
        total_time, _ = results[w]
        speedup = results[1][0] / total_time
        efficiency = speedup / w * 100
        print(f"{w:<10} {total_time:<12.2f} {speedup:<10.2f}x {efficiency:<12.1f}%")
    print("="*72)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Diagnose multiprocessing behaviour for Auto-PINN.")
    parser.add_argument("--workers", type=int, default=4, help="Number of worker processes to launch.")
    parser.add_argument(
        "--tasks",
        type=int,
        default=4,
        help="Number of probe tasks to execute (>= workers to show overlap).",
    )
    parser.add_argument(
        "--cpu-sleep",
        type=float,
        default=0.25,
        help="Seconds of CPU-side sleep to inject before GPU work (simulates data prep).",
    )
    parser.add_argument(
        "--matmul-size",
        type=int,
        default=1024,
        help="Size of the square matrices used in each GPU matmul probe.",
    )
    parser.add_argument(
        "--benchmark-fixed",
        action="store_true",
        help="Run fixed-total-tasks benchmark (GA-like wall time).",
    )
    parser.add_argument(
        "--total-tasks",
        type=int,
        default=20,
        help="Total tasks to run in --benchmark-fixed mode (default: 20).",
    )
    parser.add_argument(
        "--benchmark",
        action="store_true",
        help="Run full workers scalability benchmark (1 to max-workers)."
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=8,
        help="Maximum workers to test in benchmark mode (default: 8)."
    )
    parser.add_argument(
        "--tasks-per-worker",
        type=int,
        default=2,
        help="Number of tasks per worker in benchmark mode (default: 2)."
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=1000,
        help="Number of training epochs per task in benchmark (default: 1000)."
    )
    args = parser.parse_args()

    if args.benchmark_fixed:
        benchmark_fixed_tasks(
            max_workers=args.max_workers,
            total_tasks=args.total_tasks,
            epochs=args.epochs,
        )
    elif args.benchmark:
        # è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•
        benchmark_workers(
            max_workers=args.max_workers,
            tasks_per_worker=args.tasks_per_worker,
            epochs=args.epochs
        )
    else:
        # è¿è¡Œç®€å•è¯Šæ–­ï¼ˆè½»é‡çº§æ¢æµ‹ï¼‰
        if args.workers < 1:
            parser.error("workers must be >= 1")
        if args.tasks < args.workers:
            parser.error("tasks must be >= workers to observe overlap")
        run_probe(args.workers, args.tasks, args.cpu_sleep, args.matmul_size)
